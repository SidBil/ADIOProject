{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fbd128bd",
      "metadata": {},
      "source": [
        "# LoRA Fine-tuning — Whisper Small on TORGO\n",
        "\n",
        "Fine-tunes Whisper Small on TORGO using LoRA. Config from `config.yaml`. Notebook lives in `asr/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "51bfc75f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sidharthbildikar/Desktop/code/ASR Project/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import importlib, accelerate\n",
        "importlib.reload(accelerate)\n",
        "\n",
        "import numpy as np\n",
        "import yaml, torch, evaluate\n",
        "from pathlib import Path\n",
        "from datasets import load_from_disk\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9a531621",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "openai/whisper-small\n"
          ]
        }
      ],
      "source": [
        "PROJECT_ROOT = Path.cwd().parent\n",
        "with open(Path.cwd() / \"config.yaml\") as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "print(cfg[\"model\"][\"name\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "435ea1f8",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'dataset_path'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataset = load_from_disk(\u001b[38;5;28mstr\u001b[39m(PROJECT_ROOT / \u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset_path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(dataset)\n",
            "\u001b[31mKeyError\u001b[39m: 'dataset_path'"
          ]
        }
      ],
      "source": [
        "dataset = load_from_disk(str(PROJECT_ROOT / cfg[\"data\"][\"dataset_path\"]))\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2f663e92",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading weights: 100%|██████████| 479/479 [00:00<00:00, 1426.23it/s, Materializing param=model.encoder.layers.11.self_attn_layer_norm.weight]   \n"
          ]
        }
      ],
      "source": [
        "processor = WhisperProcessor.from_pretrained(cfg[\"model\"][\"name\"], language=cfg[\"model\"][\"language\"], task=cfg[\"model\"][\"task\"])\n",
        "model = WhisperForConditionalGeneration.from_pretrained(cfg[\"model\"][\"name\"])\n",
        "model.config.forced_decoder_ids = None\n",
        "model.config.suppress_tokens = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d23ec71d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1,769,472 || all params: 243,504,384 || trainable%: 0.7267\n"
          ]
        }
      ],
      "source": [
        "model.config.use_cache = False\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "lora = cfg[\"lora\"]\n",
        "model = get_peft_model(model, LoraConfig(r=lora[\"r\"], lora_alpha=lora[\"alpha\"], lora_dropout=lora[\"dropout\"], target_modules=lora[\"target_modules\"], bias=\"none\", task_type=TaskType.SEQ_2_SEQ_LM))\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "63d16fe8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Preparing: 100%|██████████| 14896/14896 [01:19<00:00, 186.64 examples/s]\n",
            "Preparing: 100%|██████████| 1656/1656 [00:08<00:00, 188.83 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_features', 'labels'],\n",
            "        num_rows: 14896\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_features', 'labels'],\n",
            "        num_rows: 1656\n",
            "    })\n",
            "})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "sr = cfg[\"data\"][\"sampling_rate\"]\n",
        "max_samples = int(cfg[\"data\"][\"max_audio_length\"] * sr)\n",
        "\n",
        "def prepare(batch):\n",
        "    audio = batch[\"audio\"]\n",
        "    array = np.asarray(audio[\"array\"], dtype=np.float32) if isinstance(audio, dict) else np.asarray(audio, dtype=np.float32)\n",
        "    array = array[:max_samples]\n",
        "    padded = np.zeros(max_samples, dtype=np.float32)\n",
        "    padded[:len(array)] = array\n",
        "    batch[\"input_features\"] = processor.feature_extractor(padded, sampling_rate=sr, return_tensors=\"np\").input_features[0]\n",
        "    batch[\"labels\"] = processor.tokenizer(batch[\"transcription\"]).input_ids\n",
        "    return batch\n",
        "\n",
        "dataset = dataset.map(prepare, remove_columns=dataset[\"train\"].column_names, desc=\"Preparing\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "c4bec07b",
      "metadata": {},
      "outputs": [],
      "source": [
        "pad_id = processor.tokenizer.pad_token_id\n",
        "\n",
        "def collate(batch):\n",
        "    feats = torch.stack([torch.tensor(x[\"input_features\"]) for x in batch])\n",
        "    labels = [torch.tensor(x[\"labels\"]) for x in batch]\n",
        "    labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n",
        "    return {\"input_features\": feats, \"labels\": labels}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ee33c42b",
      "metadata": {},
      "outputs": [],
      "source": [
        "wer_metric = evaluate.load(\"wer\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = np.where(pred.label_ids != -100, pred.label_ids, pad_id)\n",
        "    pred_str = processor.tokenizer.batch_decode(pred.predictions, skip_special_tokens=True)\n",
        "    label_str = processor.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    return {\"wer\": wer_metric.compute(predictions=pred_str, references=label_str)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "d9473fda",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`logging_dir` is deprecated and will be removed in v5.2. Please set `TENSORBOARD_LOGGING_DIR` instead.\n"
          ]
        }
      ],
      "source": [
        "tc = cfg[\"training\"]\n",
        "model_dir = str(PROJECT_ROOT / cfg[\"output\"][\"model_dir\"])\n",
        "log_dir = str(PROJECT_ROOT / cfg[\"output\"][\"log_dir\"])\n",
        "Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
        "Path(log_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=model_dir,\n",
        "    remove_unused_columns=False,\n",
        "    per_device_train_batch_size=tc[\"batch_size\"],\n",
        "    per_device_eval_batch_size=tc[\"batch_size\"],\n",
        "    num_train_epochs=tc[\"epochs\"],\n",
        "    learning_rate=tc[\"learning_rate\"],\n",
        "    warmup_steps=tc[\"warmup_steps\"],\n",
        "    fp16=tc[\"fp16\"],\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=tc[\"eval_steps\"],\n",
        "    save_steps=tc[\"save_steps\"],\n",
        "    save_total_limit=2,\n",
        "    gradient_accumulation_steps=tc[\"gradient_accumulation_steps\"],\n",
        "    logging_dir=log_dir,\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=tc[\"metric_for_best_model\"],\n",
        "    greater_is_better=tc[\"greater_is_better\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e300e9f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    data_collator=collate,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=tc[\"early_stopping_patience\"])] if tc.get(\"early_stopping_patience\") else [],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "5af2127e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='501' max='2793' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 501/2793 2:47:04 < 12:47:24, 0.05 it/s, Epoch 0.54/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='247' max='1656' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 247/1656 27:41 < 2:38:39, 0.15 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "RuntimeError",
          "evalue": "MPS backend out of memory (MPS allocated: 19.77 GiB, other allocations: 226.48 MiB, max allowed: 20.13 GiB). Tried to allocate 1.06 GiB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/code/ASR Project/venv/lib/python3.13/site-packages/transformers/trainer.py:2170\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2168\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2171\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/code/ASR Project/venv/lib/python3.13/site-packages/transformers/trainer.py:2608\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2606\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.epoch = epoch + (step + \u001b[32m1\u001b[39m) / steps_in_epoch\n\u001b[32m   2607\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_step_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2608\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2609\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2610\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2611\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2612\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2613\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2614\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2615\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2617\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2618\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2619\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_substep_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/code/ASR Project/venv/lib/python3.13/site-packages/transformers/trainer.py:3021\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[39m\n\u001b[32m   3019\u001b[39m metrics = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3020\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.control.should_evaluate:\n\u001b[32m-> \u001b[39m\u001b[32m3021\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3022\u001b[39m     is_new_best_metric = \u001b[38;5;28mself\u001b[39m._determine_best_metric(metrics=metrics, trial=trial)\n\u001b[32m   3024\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_strategy == SaveStrategy.BEST:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/code/ASR Project/venv/lib/python3.13/site-packages/transformers/trainer.py:2970\u001b[39m, in \u001b[36mTrainer._evaluate\u001b[39m\u001b[34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[39m\n\u001b[32m   2969\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2970\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2971\u001b[39m     \u001b[38;5;28mself\u001b[39m._report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m.state.global_step, metrics)\n\u001b[32m   2973\u001b[39m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/code/ASR Project/venv/lib/python3.13/site-packages/transformers/trainer_seq2seq.py:191\u001b[39m, in \u001b[36mSeq2SeqTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28mself\u001b[39m.gather_function = \u001b[38;5;28mself\u001b[39m.accelerator.gather\n\u001b[32m    190\u001b[39m \u001b[38;5;28mself\u001b[39m._gen_kwargs = gen_kwargs\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/code/ASR Project/venv/lib/python3.13/site-packages/transformers/trainer.py:4290\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4286\u001b[39m     eval_dataloader = tpu_spmd_dataloader(eval_dataloader)\n\u001b[32m   4288\u001b[39m start_time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m4290\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluation_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4291\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4292\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4293\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[32m   4294\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[32m   4295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4296\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4298\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4300\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n\u001b[32m   4301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_model_preparation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/code/ASR Project/venv/lib/python3.13/site-packages/transformers/trainer.py:4505\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4503\u001b[39m     logits = \u001b[38;5;28mself\u001b[39m.gather_function(logits)\n\u001b[32m   4504\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.batch_eval_metrics \u001b[38;5;129;01mor\u001b[39;00m description == \u001b[33m\"\u001b[39m\u001b[33mPrediction\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m4505\u001b[39m         \u001b[43mall_preds\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4507\u001b[39m     labels = \u001b[38;5;28mself\u001b[39m.gather_function(labels)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/code/ASR Project/venv/lib/python3.13/site-packages/transformers/trainer_pt_utils.py:315\u001b[39m, in \u001b[36mEvalLoopContainer.add\u001b[39m\u001b[34m(self, tensors)\u001b[39m\n\u001b[32m    313\u001b[39m     \u001b[38;5;28mself\u001b[39m.tensors = tensors \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.do_nested_concat \u001b[38;5;28;01melse\u001b[39;00m [tensors]\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.do_nested_concat:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     \u001b[38;5;28mself\u001b[39m.tensors = \u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    317\u001b[39m     \u001b[38;5;28mself\u001b[39m.tensors.append(tensors)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/code/ASR Project/venv/lib/python3.13/site-packages/transformers/trainer_pt_utils.py:129\u001b[39m, in \u001b[36mnested_concat\u001b[39m\u001b[34m(tensors, new_tensors, padding_index)\u001b[39m\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(new_tensors), (\n\u001b[32m    126\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected `tensors` and `new_tensors` to have the same type but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(new_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    127\u001b[39m     )\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch.Tensor):\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_pad_and_concatenate(tensors, new_tensors, padding_index=padding_index)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/code/ASR Project/venv/lib/python3.13/site-packages/transformers/trainer_pt_utils.py:129\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(new_tensors), (\n\u001b[32m    126\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected `tensors` and `new_tensors` to have the same type but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(new_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    127\u001b[39m     )\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch.Tensor):\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_pad_and_concatenate(tensors, new_tensors, padding_index=padding_index)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/code/ASR Project/venv/lib/python3.13/site-packages/transformers/trainer_pt_utils.py:131\u001b[39m, in \u001b[36mnested_concat\u001b[39m\u001b[34m(tensors, new_tensors, padding_index)\u001b[39m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(nested_concat(t, n, padding_index=padding_index) \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch.Tensor):\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_pad_and_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, Mapping):\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\n\u001b[32m    134\u001b[39m         {k: nested_concat(t, new_tensors[k], padding_index=padding_index) \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensors.items()}\n\u001b[32m    135\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/code/ASR Project/venv/lib/python3.13/site-packages/transformers/trainer_pt_utils.py:89\u001b[39m, in \u001b[36mtorch_pad_and_concatenate\u001b[39m\u001b[34m(tensor1, tensor2, padding_index)\u001b[39m\n\u001b[32m     86\u001b[39m tensor2 = atleast_1d(tensor2)\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor1.shape) == \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m tensor1.shape[\u001b[32m1\u001b[39m] == tensor2.shape[\u001b[32m1\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Let's figure out the new shape\u001b[39;00m\n\u001b[32m     92\u001b[39m new_shape = (tensor1.shape[\u001b[32m0\u001b[39m] + tensor2.shape[\u001b[32m0\u001b[39m], \u001b[38;5;28mmax\u001b[39m(tensor1.shape[\u001b[32m1\u001b[39m], tensor2.shape[\u001b[32m1\u001b[39m])) + tensor1.shape[\u001b[32m2\u001b[39m:]\n",
            "\u001b[31mRuntimeError\u001b[39m: MPS backend out of memory (MPS allocated: 19.77 GiB, other allocations: 226.48 MiB, max allowed: 20.13 GiB). Tried to allocate 1.06 GiB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "855f2a49",
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save_model(model_dir)\n",
        "processor.save_pretrained(model_dir)\n",
        "print(f\"Saved to {model_dir}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
