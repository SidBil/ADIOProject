{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ecd7ac0d",
      "metadata": {
        "id": "ecd7ac0d"
      },
      "source": [
        "# Audio Preprocessing Tutorial (TORGO → Whisper Fine-tuning)\n",
        "\n",
        "This notebook explains the script **`audio_preprocessing.py`** step-by-step.\n",
        "\n",
        "The script’s goal is to:\n",
        "1. **Load** a Hugging Face dataset saved on disk (created earlier by `data_loader.py`)\n",
        "2. **Preprocess** each audio clip (resample → normalize → trim silence → filter by duration)\n",
        "3. **Optionally augment** training audio (speed / noise / pitch)\n",
        "4. **Write** the resulting `.wav` files into an output folder structure\n",
        "5. **Save stats** about how many samples were processed / filtered / augmented"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2340f9b3",
      "metadata": {
        "id": "2340f9b3"
      },
      "source": [
        "## 0) Imports and dependencies\n",
        "\n",
        "The original script relies on:\n",
        "\n",
        "- `librosa` for audio DSP operations (resample, trim, time-stretch, pitch-shift)\n",
        "- `numpy` for numeric array operations\n",
        "- `soundfile` for writing `.wav` files\n",
        "- `datasets` for loading a dataset saved with Hugging Face Datasets and casting audio sampling rate\n",
        "\n",
        "If you run this notebook in an environment missing these libraries, install them (example):\n",
        "- `pip install librosa soundfile datasets`\n",
        "\n",
        "(Installation commands are not executed automatically here.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0a5f3ad3",
      "metadata": {
        "id": "0a5f3ad3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sidharthbildikar/Desktop/code/ASR Project/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# If you don't have them installed in your environment, install via pip:\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from datasets import load_from_disk, Audio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1412115e",
      "metadata": {
        "id": "1412115e"
      },
      "source": [
        "## 1) Core preprocessing functions\n",
        "\n",
        "The preprocessing pipeline is built from small functions.  \n",
        "Each function is easy to test independently, and together they form a reliable pipeline.\n",
        "\n",
        "### 1.1 `resample(audio, orig_sr, target_sr=16000)`\n",
        "- **Why?** Whisper models typically expect **16 kHz** audio.\n",
        "- If the audio is already at the target rate, return it unchanged.\n",
        "- Otherwise, use `librosa.resample` to convert sample rate.\n",
        "\n",
        "### 1.2 `normalize_amplitude(audio)`\n",
        "- **Why?** Different recordings have different volumes.\n",
        "- This scales audio so the maximum absolute value becomes `1.0` (range `[-1, 1]`).\n",
        "\n",
        "### 1.3 `trim_silence(audio, sr, top_db=40)`\n",
        "- **Why?** Many datasets have leading/trailing silence.\n",
        "- `librosa.effects.trim` removes quiet segments at the beginning and end.\n",
        "\n",
        "### 1.4 `is_valid_duration(audio, sr, min_sec=0.5, max_sec=30.0)`\n",
        "- **Why?** Extremely short clips often contain little speech; very long clips can be slow to train on.\n",
        "- Returns `True` only if duration is in the desired range.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8791620f",
      "metadata": {
        "id": "8791620f"
      },
      "outputs": [],
      "source": [
        "def resample(audio: np.ndarray, orig_sr: int, target_sr: int = 16000) -> np.ndarray:\n",
        "    \"\"\"Resample audio to target sample rate.\"\"\"\n",
        "    if orig_sr == target_sr:\n",
        "        return audio\n",
        "    return librosa.resample(audio, orig_sr=orig_sr, target_sr=target_sr)\n",
        "\n",
        "\n",
        "def normalize_amplitude(audio: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Normalize audio amplitude to [-1, 1].\"\"\"\n",
        "    peak = np.max(np.abs(audio))\n",
        "    if peak > 0:\n",
        "        audio = audio / peak\n",
        "    return audio\n",
        "\n",
        "\n",
        "def trim_silence(audio: np.ndarray, sr: int, top_db: int = 40) -> np.ndarray:\n",
        "    \"\"\"Trim leading and trailing silence.\"\"\"\n",
        "    trimmed, _ = librosa.effects.trim(audio, top_db=top_db)\n",
        "    return trimmed\n",
        "\n",
        "\n",
        "def is_valid_duration(audio: np.ndarray, sr: int, min_sec: float = 0.5, max_sec: float = 30.0) -> bool:\n",
        "    \"\"\"Check if audio duration is within acceptable range.\"\"\"\n",
        "    duration = len(audio) / sr\n",
        "    return min_sec <= duration <= max_sec\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4516191",
      "metadata": {
        "id": "f4516191"
      },
      "source": [
        "## 2) Augmentation functions\n",
        "\n",
        "Augmentation increases training diversity by creating plausible variations of the same utterance.\n",
        "\n",
        "> In the original script, augmentation is applied **only to the training split**.\n",
        "\n",
        "### 2.1 Speed perturbation: `augment_speed(audio, sr, rate)`\n",
        "- Uses `librosa.effects.time_stretch`\n",
        "- `rate < 1` → slower (longer)\n",
        "- `rate > 1` → faster (shorter)\n",
        "\n",
        "### 2.2 Pitch shift: `augment_pitch(audio, sr, n_steps)`\n",
        "- Shifts pitch up/down by a number of semitones\n",
        "- Useful for speaker variability\n",
        "\n",
        "### 2.3 Add noise: `augment_noise(audio, snr_db)`\n",
        "- Adds Gaussian noise to achieve a target **SNR** (signal-to-noise ratio)\n",
        "- Lower SNR → noisier audio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8699dda4",
      "metadata": {
        "id": "8699dda4"
      },
      "outputs": [],
      "source": [
        "def augment_speed(audio: np.ndarray, sr: int, rate: float) -> np.ndarray:\n",
        "    \"\"\"Apply speed perturbation (time-stretch without pitch change).\"\"\"\n",
        "    return librosa.effects.time_stretch(audio, rate=rate)\n",
        "\n",
        "\n",
        "def augment_pitch(audio: np.ndarray, sr: int, n_steps: float) -> np.ndarray:\n",
        "    \"\"\"Shift pitch by n_steps semitones.\"\"\"\n",
        "    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
        "\n",
        "\n",
        "def augment_noise(audio: np.ndarray, snr_db: float = 20.0) -> np.ndarray:\n",
        "    \"\"\"Add Gaussian noise at a given SNR.\"\"\"\n",
        "    signal_power = np.mean(audio ** 2)\n",
        "    noise_power = signal_power / (10 ** (snr_db / 10))\n",
        "    noise = np.random.normal(0, np.sqrt(noise_power), len(audio))\n",
        "    return audio + noise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08704a5a",
      "metadata": {
        "id": "08704a5a"
      },
      "source": [
        "## 3) `preprocess_sample`: the full preprocessing pipeline\n",
        "\n",
        "This function ties together the earlier helpers:\n",
        "\n",
        "1. Resample to `target_sr` (default **16 kHz**)\n",
        "2. Normalize amplitude\n",
        "3. Trim leading/trailing silence\n",
        "4. Filter samples outside a duration range  \n",
        "   - If invalid, return `None` so the caller can **skip** the sample\n",
        "\n",
        "Returning `None` is a clean pattern for *filtering* in pipelines.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "38092cda",
      "metadata": {
        "id": "38092cda"
      },
      "outputs": [],
      "source": [
        "def preprocess_sample(audio: np.ndarray, sr: int, target_sr: int = 16000) -> np.ndarray | None:\n",
        "    \"\"\"Apply full preprocessing pipeline to a single audio sample.\n",
        "\n",
        "    Returns None if the sample should be filtered out.\n",
        "    \"\"\"\n",
        "    audio = resample(audio, sr, target_sr)\n",
        "    audio = normalize_amplitude(audio)\n",
        "    audio = trim_silence(audio, target_sr)\n",
        "\n",
        "    if not is_valid_duration(audio, target_sr):\n",
        "        return None\n",
        "\n",
        "    return audio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a429ecbe",
      "metadata": {
        "id": "a429ecbe"
      },
      "source": [
        "## 4) `augment_sample`: generating augmented variants\n",
        "\n",
        "This function returns a **list of (suffix, audio_array)** pairs so the caller can name files like:\n",
        "\n",
        "- `sample_00010_speed09.wav`\n",
        "- `sample_00010_noise15.wav`\n",
        "- `sample_00010_pitch_up2.wav`\n",
        "\n",
        "This is convenient because the dataset loop doesn't need to know augmentation details — it only:\n",
        "- calls `augment_sample(...)`\n",
        "- writes each returned audio to disk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "043b6d2d",
      "metadata": {
        "id": "043b6d2d"
      },
      "outputs": [],
      "source": [
        "def augment_sample(audio: np.ndarray, sr: int) -> list[tuple[str, np.ndarray]]:\n",
        "    \"\"\"Generate augmented versions of a single audio sample.\n",
        "\n",
        "    Returns list of (suffix, augmented_audio) tuples.\n",
        "    \"\"\"\n",
        "    augmented = []\n",
        "\n",
        "    # Speed perturbation\n",
        "    augmented.append((\"speed09\", augment_speed(audio, sr, rate=0.9)))\n",
        "    augmented.append((\"speed11\", augment_speed(audio, sr, rate=1.1)))\n",
        "\n",
        "    # Background noise\n",
        "    augmented.append((\"noise20\", augment_noise(audio, snr_db=20.0)))\n",
        "    augmented.append((\"noise15\", augment_noise(audio, snr_db=15.0)))\n",
        "\n",
        "    # Pitch shifting\n",
        "    augmented.append((\"pitch_down2\", augment_pitch(audio, sr, n_steps=-2)))\n",
        "    augmented.append((\"pitch_up2\", augment_pitch(audio, sr, n_steps=2)))\n",
        "\n",
        "    return augmented\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afc018fd",
      "metadata": {
        "id": "afc018fd"
      },
      "source": [
        "## 5) `process_dataset`: the main workflow\n",
        "\n",
        "This is the “engine” of the script.\n",
        "\n",
        "### Expected input layout\n",
        "The function expects:\n",
        "- `input_dir / \"torgo_dataset\"`: a Hugging Face dataset saved with `save_to_disk`\n",
        "- Optional `input_dir / \"splits.json\"`: informational stats (printed only)\n",
        "\n",
        "### What it does\n",
        "For each split (e.g., `train`, `validation`, `test`):\n",
        "1. Create output folder `output_dir / split_name`\n",
        "2. Iterate samples:\n",
        "   - read audio array + sampling rate\n",
        "   - run `preprocess_sample`\n",
        "   - if `None` → count as filtered, skip\n",
        "   - else write processed `.wav`\n",
        "   - if split is **train** and augmentation enabled → write augmented `.wav`s\n",
        "3. Print progress every 100 samples\n",
        "4. Save `preprocessing_stats.json` into the output directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d8b2be79",
      "metadata": {
        "id": "d8b2be79"
      },
      "outputs": [],
      "source": [
        "def process_dataset(input_dir: Path, output_dir: Path, target_sr: int = 16000, do_augment: bool = True):\n",
        "    \"\"\"Process the full TORGO dataset: preprocess and optionally augment.\n",
        "\n",
        "    Expects the dataset saved via data_loader.py at input_dir/torgo_dataset.\n",
        "    \"\"\"\n",
        "    dataset_path = input_dir / \"torgo_dataset\"\n",
        "    if not dataset_path.exists():\n",
        "        raise FileNotFoundError(\n",
        "            f\"Dataset not found at {dataset_path}. \"\n",
        "            \"Run data_loader.py first to download the dataset.\"\n",
        "        )\n",
        "\n",
        "    dataset = load_from_disk(str(dataset_path))\n",
        "    dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=target_sr))\n",
        "\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Load split info (for reference)\n",
        "    splits_path = input_dir / \"splits.json\"\n",
        "    if splits_path.exists():\n",
        "        with open(splits_path) as f:\n",
        "            split_data = json.load(f)\n",
        "            print(f\"Dataset stats: {split_data.get('stats', {})}\")\n",
        "\n",
        "    stats = {\"processed\": 0, \"filtered\": 0, \"augmented\": 0}\n",
        "\n",
        "    for split_name in dataset:\n",
        "        print(f\"\\nProcessing split: {split_name}\")\n",
        "        split_dir = output_dir / split_name\n",
        "        split_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        for i, sample in enumerate(dataset[split_name]):\n",
        "            audio_data = sample[\"audio\"][\"array\"]\n",
        "            sr = sample[\"audio\"][\"sampling_rate\"]\n",
        "\n",
        "            processed = preprocess_sample(audio_data, sr, target_sr)\n",
        "            if processed is None:\n",
        "                stats[\"filtered\"] += 1\n",
        "                continue\n",
        "\n",
        "            # Save processed audio\n",
        "            out_path = split_dir / f\"sample_{i:05d}.wav\"\n",
        "            sf.write(str(out_path), processed, target_sr)\n",
        "            stats[\"processed\"] += 1\n",
        "\n",
        "            # Augment only training data\n",
        "            if do_augment and split_name == \"train\":\n",
        "                for suffix, aug_audio in augment_sample(processed, target_sr):\n",
        "                    aug_path = split_dir / f\"sample_{i:05d}_{suffix}.wav\"\n",
        "                    sf.write(str(aug_path), aug_audio, target_sr)\n",
        "                    stats[\"augmented\"] += 1\n",
        "\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(f\"  Processed {i + 1} samples...\")\n",
        "\n",
        "    print(\n",
        "        f\"\\nDone. Processed: {stats['processed']}, \"\n",
        "        f\"Filtered: {stats['filtered']}, Augmented: {stats['augmented']}\"\n",
        "    )\n",
        "\n",
        "    # Save stats\n",
        "    with open(output_dir / \"preprocessing_stats.json\", \"w\") as f:\n",
        "        json.dump(stats, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01fe55e3",
      "metadata": {
        "id": "01fe55e3"
      },
      "source": [
        "## 6) `main()`: command-line interface\n",
        "\n",
        "The `main()` function:\n",
        "\n",
        "1. Defines command-line arguments:\n",
        "   - `--input`: folder containing `torgo_dataset/`\n",
        "   - `--output`: where to write processed audio\n",
        "   - `--sr`: target sample rate (default 16000)\n",
        "   - `--no-augment`: disables augmentation\n",
        "2. Parses args\n",
        "3. Calls `process_dataset(...)`\n",
        "\n",
        "The final:\n",
        "\n",
        "```python\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```\n",
        "\n",
        "means: *only run `main()` when this file is executed as a script*, not when imported as a module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c1d43d47",
      "metadata": {
        "id": "c1d43d47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset stats: {'train': {'total': 13240, 'by_status': {'1': 8782, '0': 4458}}, 'validation': {'total': 1656, 'by_status': {'0': 558, '1': 1098}}, 'test': {'total': 1656, 'by_status': {'1': 1098, '0': 558}}}\n",
            "\n",
            "Processing split: train\n",
            "  Processed 100 samples...\n",
            "  Processed 200 samples...\n",
            "  Processed 300 samples...\n",
            "  Processed 400 samples...\n",
            "  Processed 500 samples...\n",
            "  Processed 600 samples...\n",
            "  Processed 700 samples...\n",
            "  Processed 800 samples...\n",
            "  Processed 900 samples...\n",
            "  Processed 1000 samples...\n",
            "  Processed 1100 samples...\n",
            "  Processed 1200 samples...\n",
            "  Processed 1300 samples...\n",
            "  Processed 1400 samples...\n",
            "  Processed 1500 samples...\n",
            "  Processed 1600 samples...\n",
            "  Processed 1700 samples...\n",
            "  Processed 1800 samples...\n",
            "  Processed 1900 samples...\n",
            "  Processed 2000 samples...\n",
            "  Processed 2100 samples...\n",
            "  Processed 2200 samples...\n",
            "  Processed 2300 samples...\n",
            "  Processed 2400 samples...\n",
            "  Processed 2500 samples...\n",
            "  Processed 2600 samples...\n",
            "  Processed 2700 samples...\n",
            "  Processed 2800 samples...\n",
            "  Processed 2900 samples...\n",
            "  Processed 3000 samples...\n",
            "  Processed 3100 samples...\n",
            "  Processed 3200 samples...\n",
            "  Processed 3300 samples...\n",
            "  Processed 3400 samples...\n",
            "  Processed 3500 samples...\n",
            "  Processed 3600 samples...\n",
            "  Processed 3700 samples...\n",
            "  Processed 3800 samples...\n",
            "  Processed 3900 samples...\n",
            "  Processed 4000 samples...\n",
            "  Processed 4100 samples...\n",
            "  Processed 4200 samples...\n",
            "  Processed 4300 samples...\n",
            "  Processed 4400 samples...\n",
            "  Processed 4500 samples...\n",
            "  Processed 4600 samples...\n",
            "  Processed 4700 samples...\n",
            "  Processed 4800 samples...\n",
            "  Processed 4900 samples...\n",
            "  Processed 5000 samples...\n",
            "  Processed 5100 samples...\n",
            "  Processed 5200 samples...\n",
            "  Processed 5300 samples...\n",
            "  Processed 5400 samples...\n",
            "  Processed 5500 samples...\n",
            "  Processed 5600 samples...\n",
            "  Processed 5700 samples...\n",
            "  Processed 5800 samples...\n",
            "  Processed 5900 samples...\n",
            "  Processed 6000 samples...\n",
            "  Processed 6100 samples...\n",
            "  Processed 6200 samples...\n",
            "  Processed 6300 samples...\n",
            "  Processed 6400 samples...\n",
            "  Processed 6500 samples...\n",
            "  Processed 6600 samples...\n",
            "  Processed 6700 samples...\n",
            "  Processed 6800 samples...\n",
            "  Processed 6900 samples...\n",
            "  Processed 7000 samples...\n",
            "  Processed 7100 samples...\n",
            "  Processed 7200 samples...\n",
            "  Processed 7300 samples...\n",
            "  Processed 7400 samples...\n",
            "  Processed 7500 samples...\n",
            "  Processed 7600 samples...\n",
            "  Processed 7700 samples...\n",
            "  Processed 7800 samples...\n",
            "  Processed 7900 samples...\n",
            "  Processed 8000 samples...\n",
            "  Processed 8100 samples...\n",
            "  Processed 8200 samples...\n",
            "  Processed 8300 samples...\n",
            "  Processed 8400 samples...\n",
            "  Processed 8500 samples...\n",
            "  Processed 8600 samples...\n",
            "  Processed 8700 samples...\n",
            "  Processed 8800 samples...\n",
            "  Processed 8900 samples...\n",
            "  Processed 9000 samples...\n",
            "  Processed 9100 samples...\n",
            "  Processed 9200 samples...\n",
            "  Processed 9300 samples...\n",
            "  Processed 9400 samples...\n",
            "  Processed 9500 samples...\n",
            "  Processed 9600 samples...\n",
            "  Processed 9700 samples...\n",
            "  Processed 9800 samples...\n",
            "  Processed 9900 samples...\n",
            "  Processed 10000 samples...\n",
            "  Processed 10100 samples...\n",
            "  Processed 10200 samples...\n",
            "  Processed 10300 samples...\n",
            "  Processed 10400 samples...\n",
            "  Processed 10500 samples...\n",
            "  Processed 10600 samples...\n",
            "  Processed 10700 samples...\n",
            "  Processed 10800 samples...\n",
            "  Processed 10900 samples...\n",
            "  Processed 11000 samples...\n",
            "  Processed 11100 samples...\n",
            "  Processed 11200 samples...\n",
            "  Processed 11300 samples...\n",
            "  Processed 11400 samples...\n",
            "  Processed 11500 samples...\n",
            "  Processed 11600 samples...\n",
            "  Processed 11700 samples...\n",
            "  Processed 11800 samples...\n",
            "  Processed 11900 samples...\n",
            "  Processed 12000 samples...\n",
            "  Processed 12100 samples...\n",
            "  Processed 12200 samples...\n",
            "  Processed 12300 samples...\n",
            "  Processed 12400 samples...\n",
            "  Processed 12500 samples...\n",
            "  Processed 12600 samples...\n",
            "  Processed 12700 samples...\n",
            "  Processed 12800 samples...\n",
            "  Processed 12900 samples...\n",
            "  Processed 13000 samples...\n",
            "  Processed 13100 samples...\n",
            "  Processed 13200 samples...\n",
            "\n",
            "Processing split: validation\n",
            "  Processed 100 samples...\n",
            "  Processed 200 samples...\n",
            "  Processed 300 samples...\n",
            "  Processed 400 samples...\n",
            "  Processed 600 samples...\n",
            "  Processed 700 samples...\n",
            "  Processed 800 samples...\n",
            "  Processed 900 samples...\n",
            "  Processed 1000 samples...\n",
            "  Processed 1100 samples...\n",
            "  Processed 1200 samples...\n",
            "  Processed 1300 samples...\n",
            "  Processed 1400 samples...\n",
            "  Processed 1500 samples...\n",
            "  Processed 1600 samples...\n",
            "\n",
            "Processing split: test\n",
            "  Processed 100 samples...\n",
            "  Processed 200 samples...\n",
            "  Processed 300 samples...\n",
            "  Processed 400 samples...\n",
            "  Processed 500 samples...\n",
            "  Processed 600 samples...\n",
            "  Processed 700 samples...\n",
            "  Processed 800 samples...\n",
            "  Processed 900 samples...\n",
            "  Processed 1000 samples...\n",
            "  Processed 1100 samples...\n",
            "  Processed 1200 samples...\n",
            "  Processed 1300 samples...\n",
            "  Processed 1400 samples...\n",
            "  Processed 1500 samples...\n",
            "  Processed 1600 samples...\n",
            "\n",
            "Done. Processed: 16539, Filtered: 13, Augmented: 79386\n"
          ]
        }
      ],
      "source": [
        "process_dataset(\n",
        "    input_dir=Path(\"torgo\"),\n",
        "    output_dir=Path(\"torgo/processed\"),\n",
        "    target_sr=16000,\n",
        "    do_augment=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6264e9e7",
      "metadata": {},
      "source": [
        "## 7) Generate metadata JSON for processed samples\n",
        "\n",
        "The preprocessing step above writes only `.wav` files — no per-sample metadata is preserved.\n",
        "This cell reconstructs metadata from the original dataset and writes `metadata.json` into the\n",
        "processed output directory.\n",
        "\n",
        "For each processed `.wav` (including augmented variants), the JSON records:\n",
        "- `transcription` — the ground-truth text\n",
        "- `speech_status` — `\"dysarthria\"` or `\"healthy\"`\n",
        "- `gender` — speaker gender\n",
        "- `duration` — original duration in seconds\n",
        "\n",
        "The file is keyed by split → filename, making it easy to look up any sample's metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8495865a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: 92617 entries (31171 dysarthria, 61446 healthy)\n",
            "validation: 1653 entries (556 dysarthria, 1097 healthy)\n",
            "test: 1655 entries (558 dysarthria, 1097 healthy)\n",
            "\n",
            "Metadata saved to torgo/processed/metadata.json\n"
          ]
        }
      ],
      "source": [
        "dataset_path = Path(\"torgo/torgo_dataset\")\n",
        "output_dir = Path(\"torgo/processed\")\n",
        "target_sr = 16000\n",
        "\n",
        "dataset = load_from_disk(str(dataset_path))\n",
        "status_labels = dataset[\"train\"].features[\"speech_status\"].names  # [\"dysarthria\", \"healthy\"]\n",
        "\n",
        "augment_suffixes = [\"speed09\", \"speed11\", \"noise20\", \"noise15\", \"pitch_down2\", \"pitch_up2\"]\n",
        "\n",
        "metadata = {}\n",
        "\n",
        "for split_name in dataset:\n",
        "    split_dir = output_dir / split_name\n",
        "    split_metadata = {}\n",
        "\n",
        "    for i, sample in enumerate(dataset[split_name]):\n",
        "        base_name = f\"sample_{i:05d}\"\n",
        "        wav_path = split_dir / f\"{base_name}.wav\"\n",
        "\n",
        "        if not wav_path.exists():\n",
        "            continue\n",
        "\n",
        "        entry = {\n",
        "            \"transcription\": sample[\"transcription\"],\n",
        "            \"speech_status\": status_labels[sample[\"speech_status\"]],\n",
        "            \"gender\": sample[\"gender\"],\n",
        "            \"duration\": sample[\"duration\"],\n",
        "        }\n",
        "\n",
        "        split_metadata[f\"{base_name}.wav\"] = entry\n",
        "\n",
        "        if split_name == \"train\":\n",
        "            for suffix in augment_suffixes:\n",
        "                aug_path = split_dir / f\"{base_name}_{suffix}.wav\"\n",
        "                if aug_path.exists():\n",
        "                    split_metadata[f\"{base_name}_{suffix}.wav\"] = entry\n",
        "\n",
        "    metadata[split_name] = split_metadata\n",
        "    dysarthria_count = sum(1 for v in split_metadata.values() if v[\"speech_status\"] == \"dysarthria\")\n",
        "    healthy_count = sum(1 for v in split_metadata.values() if v[\"speech_status\"] == \"healthy\")\n",
        "    print(f\"{split_name}: {len(split_metadata)} entries ({dysarthria_count} dysarthria, {healthy_count} healthy)\")\n",
        "\n",
        "metadata_path = output_dir / \"metadata.json\"\n",
        "with open(metadata_path, \"w\") as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(f\"\\nMetadata saved to {metadata_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19cbcd8d",
      "metadata": {
        "id": "19cbcd8d"
      },
      "source": [
        "## 8) Summary\n",
        "\n",
        "You can think of the script as:\n",
        "\n",
        "- **Data ingestion** (load dataset from disk)\n",
        "- **Canonicalization** (resample to 16 kHz, normalize)\n",
        "- **Cleanup** (trim silence, filter duration)\n",
        "- **Training diversification** (augment *train* only)\n",
        "- **Export** (write `.wav` files + stats JSON)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [
        {
          "file_id": "1-ydFxM8zlC71glAEuXrnxKOl4H5CVkvk",
          "timestamp": 1771605352542
        }
      ]
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
