{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ecd7ac0d",
      "metadata": {
        "id": "ecd7ac0d"
      },
      "source": [
        "# Audio Preprocessing Tutorial (TORGO → Whisper Fine-tuning)\n",
        "\n",
        "This notebook explains the script **`audio_preprocessing.py`** step-by-step.\n",
        "\n",
        "The script’s goal is to:\n",
        "1. **Load** a Hugging Face dataset saved on disk (created earlier by `data_loader.py`)\n",
        "2. **Preprocess** each audio clip (resample → normalize → trim silence → filter by duration)\n",
        "3. **Optionally augment** training audio (speed / noise / pitch)\n",
        "4. **Write** the resulting `.wav` files into an output folder structure\n",
        "5. **Save stats** about how many samples were processed / filtered / augmented"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2340f9b3",
      "metadata": {
        "id": "2340f9b3"
      },
      "source": [
        "## 0) Imports and dependencies\n",
        "\n",
        "The original script relies on:\n",
        "\n",
        "- `librosa` for audio DSP operations (resample, trim, time-stretch, pitch-shift)\n",
        "- `numpy` for numeric array operations\n",
        "- `soundfile` for writing `.wav` files\n",
        "- `datasets` for loading a dataset saved with Hugging Face Datasets and casting audio sampling rate\n",
        "\n",
        "If you run this notebook in an environment missing these libraries, install them (example):\n",
        "- `pip install librosa soundfile datasets`\n",
        "\n",
        "(Installation commands are not executed automatically here.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0a5f3ad3",
      "metadata": {
        "id": "0a5f3ad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/sidharthbildikar/Desktop/code/ASR Project/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# If you don't have them installed in your environment, install via pip:\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from datasets import load_from_disk, Audio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1412115e",
      "metadata": {
        "id": "1412115e"
      },
      "source": [
        "## 1) Core preprocessing functions\n",
        "\n",
        "The preprocessing pipeline is built from small functions.  \n",
        "Each function is easy to test independently, and together they form a reliable pipeline.\n",
        "\n",
        "### 1.1 `resample(audio, orig_sr, target_sr=16000)`\n",
        "- **Why?** Whisper models typically expect **16 kHz** audio.\n",
        "- If the audio is already at the target rate, return it unchanged.\n",
        "- Otherwise, use `librosa.resample` to convert sample rate.\n",
        "\n",
        "### 1.2 `normalize_amplitude(audio)`\n",
        "- **Why?** Different recordings have different volumes.\n",
        "- This scales audio so the maximum absolute value becomes `1.0` (range `[-1, 1]`).\n",
        "\n",
        "### 1.3 `trim_silence(audio, sr, top_db=40)`\n",
        "- **Why?** Many datasets have leading/trailing silence.\n",
        "- `librosa.effects.trim` removes quiet segments at the beginning and end.\n",
        "\n",
        "### 1.4 `is_valid_duration(audio, sr, min_sec=0.5, max_sec=30.0)`\n",
        "- **Why?** Extremely short clips often contain little speech; very long clips can be slow to train on.\n",
        "- Returns `True` only if duration is in the desired range.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8791620f",
      "metadata": {
        "id": "8791620f"
      },
      "outputs": [],
      "source": [
        "def resample(audio: np.ndarray, orig_sr: int, target_sr: int = 16000) -> np.ndarray:\n",
        "    \"\"\"Resample audio to target sample rate.\"\"\"\n",
        "    if orig_sr == target_sr:\n",
        "        return audio\n",
        "    return librosa.resample(audio, orig_sr=orig_sr, target_sr=target_sr)\n",
        "\n",
        "\n",
        "def normalize_amplitude(audio: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Normalize audio amplitude to [-1, 1].\"\"\"\n",
        "    peak = np.max(np.abs(audio))\n",
        "    if peak > 0:\n",
        "        audio = audio / peak\n",
        "    return audio\n",
        "\n",
        "\n",
        "def trim_silence(audio: np.ndarray, sr: int, top_db: int = 40) -> np.ndarray:\n",
        "    \"\"\"Trim leading and trailing silence.\"\"\"\n",
        "    trimmed, _ = librosa.effects.trim(audio, top_db=top_db)\n",
        "    return trimmed\n",
        "\n",
        "\n",
        "def is_valid_duration(audio: np.ndarray, sr: int, min_sec: float = 0.5, max_sec: float = 30.0) -> bool:\n",
        "    \"\"\"Check if audio duration is within acceptable range.\"\"\"\n",
        "    duration = len(audio) / sr\n",
        "    return min_sec <= duration <= max_sec\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4516191",
      "metadata": {
        "id": "f4516191"
      },
      "source": [
        "## 2) Augmentation functions\n",
        "\n",
        "Augmentation increases training diversity by creating plausible variations of the same utterance.\n",
        "\n",
        "> In the original script, augmentation is applied **only to the training split**.\n",
        "\n",
        "### 2.1 Speed perturbation: `augment_speed(audio, sr, rate)`\n",
        "- Uses `librosa.effects.time_stretch`\n",
        "- `rate < 1` → slower (longer)\n",
        "- `rate > 1` → faster (shorter)\n",
        "\n",
        "### 2.2 Pitch shift: `augment_pitch(audio, sr, n_steps)`\n",
        "- Shifts pitch up/down by a number of semitones\n",
        "- Useful for speaker variability\n",
        "\n",
        "### 2.3 Add noise: `augment_noise(audio, snr_db)`\n",
        "- Adds Gaussian noise to achieve a target **SNR** (signal-to-noise ratio)\n",
        "- Lower SNR → noisier audio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8699dda4",
      "metadata": {
        "id": "8699dda4"
      },
      "outputs": [],
      "source": [
        "def augment_speed(audio: np.ndarray, sr: int, rate: float) -> np.ndarray:\n",
        "    \"\"\"Apply speed perturbation (time-stretch without pitch change).\"\"\"\n",
        "    return librosa.effects.time_stretch(audio, rate=rate)\n",
        "\n",
        "\n",
        "def augment_pitch(audio: np.ndarray, sr: int, n_steps: float) -> np.ndarray:\n",
        "    \"\"\"Shift pitch by n_steps semitones.\"\"\"\n",
        "    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
        "\n",
        "\n",
        "def augment_noise(audio: np.ndarray, snr_db: float = 20.0) -> np.ndarray:\n",
        "    \"\"\"Add Gaussian noise at a given SNR.\"\"\"\n",
        "    signal_power = np.mean(audio ** 2)\n",
        "    noise_power = signal_power / (10 ** (snr_db / 10))\n",
        "    noise = np.random.normal(0, np.sqrt(noise_power), len(audio))\n",
        "    return audio + noise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08704a5a",
      "metadata": {
        "id": "08704a5a"
      },
      "source": [
        "## 3) `preprocess_sample`: the full preprocessing pipeline\n",
        "\n",
        "This function ties together the earlier helpers:\n",
        "\n",
        "1. Resample to `target_sr` (default **16 kHz**)\n",
        "2. Normalize amplitude\n",
        "3. Trim leading/trailing silence\n",
        "4. Filter samples outside a duration range  \n",
        "   - If invalid, return `None` so the caller can **skip** the sample\n",
        "\n",
        "Returning `None` is a clean pattern for *filtering* in pipelines.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "38092cda",
      "metadata": {
        "id": "38092cda"
      },
      "outputs": [],
      "source": [
        "def preprocess_sample(audio: np.ndarray, sr: int, target_sr: int = 16000) -> np.ndarray | None:\n",
        "    \"\"\"Apply full preprocessing pipeline to a single audio sample.\n",
        "\n",
        "    Returns None if the sample should be filtered out.\n",
        "    \"\"\"\n",
        "    audio = resample(audio, sr, target_sr)\n",
        "    audio = normalize_amplitude(audio)\n",
        "    audio = trim_silence(audio, target_sr)\n",
        "\n",
        "    if not is_valid_duration(audio, target_sr):\n",
        "        return None\n",
        "\n",
        "    return audio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a429ecbe",
      "metadata": {
        "id": "a429ecbe"
      },
      "source": [
        "## 4) `augment_sample`: generating augmented variants\n",
        "\n",
        "This function returns a **list of (suffix, audio_array)** pairs so the caller can name files like:\n",
        "\n",
        "- `sample_00010_speed09.wav`\n",
        "- `sample_00010_noise15.wav`\n",
        "- `sample_00010_pitch_up2.wav`\n",
        "\n",
        "This is convenient because the dataset loop doesn't need to know augmentation details — it only:\n",
        "- calls `augment_sample(...)`\n",
        "- writes each returned audio to disk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "043b6d2d",
      "metadata": {
        "id": "043b6d2d"
      },
      "outputs": [],
      "source": [
        "def augment_sample(audio: np.ndarray, sr: int) -> list[tuple[str, np.ndarray]]:\n",
        "    \"\"\"Generate augmented versions of a single audio sample.\n",
        "\n",
        "    Returns list of (suffix, augmented_audio) tuples.\n",
        "    \"\"\"\n",
        "    augmented = []\n",
        "\n",
        "    # Speed perturbation\n",
        "    augmented.append((\"speed09\", augment_speed(audio, sr, rate=0.9)))\n",
        "    augmented.append((\"speed11\", augment_speed(audio, sr, rate=1.1)))\n",
        "\n",
        "    # Background noise\n",
        "    augmented.append((\"noise20\", augment_noise(audio, snr_db=20.0)))\n",
        "    augmented.append((\"noise15\", augment_noise(audio, snr_db=15.0)))\n",
        "\n",
        "    # Pitch shifting\n",
        "    augmented.append((\"pitch_down2\", augment_pitch(audio, sr, n_steps=-2)))\n",
        "    augmented.append((\"pitch_up2\", augment_pitch(audio, sr, n_steps=2)))\n",
        "\n",
        "    return augmented\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afc018fd",
      "metadata": {
        "id": "afc018fd"
      },
      "source": [
        "## 5) `process_dataset`: the main workflow\n",
        "\n",
        "This is the “engine” of the script.\n",
        "\n",
        "### Expected input layout\n",
        "The function expects:\n",
        "- `input_dir / \"torgo_dataset\"`: a Hugging Face dataset saved with `save_to_disk`\n",
        "- Optional `input_dir / \"splits.json\"`: informational stats (printed only)\n",
        "\n",
        "### What it does\n",
        "For each split (e.g., `train`, `validation`, `test`):\n",
        "1. Create output folder `output_dir / split_name`\n",
        "2. Iterate samples:\n",
        "   - read audio array + sampling rate\n",
        "   - run `preprocess_sample`\n",
        "   - if `None` → count as filtered, skip\n",
        "   - else write processed `.wav`\n",
        "   - if split is **train** and augmentation enabled → write augmented `.wav`s\n",
        "3. Print progress every 100 samples\n",
        "4. Save `preprocessing_stats.json` into the output directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d8b2be79",
      "metadata": {
        "id": "d8b2be79"
      },
      "outputs": [],
      "source": [
        "def process_dataset(input_dir: Path, output_dir: Path, target_sr: int = 16000, do_augment: bool = True):\n",
        "    \"\"\"Process the full TORGO dataset: preprocess and optionally augment.\n",
        "\n",
        "    Expects the dataset saved via data_loader.py at input_dir/torgo_dataset.\n",
        "    \"\"\"\n",
        "    dataset_path = input_dir / \"torgo_dataset\"\n",
        "    if not dataset_path.exists():\n",
        "        raise FileNotFoundError(\n",
        "            f\"Dataset not found at {dataset_path}. \"\n",
        "            \"Run data_loader.py first to download the dataset.\"\n",
        "        )\n",
        "\n",
        "    dataset = load_from_disk(str(dataset_path))\n",
        "    dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=target_sr))\n",
        "\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Load split info (for reference)\n",
        "    splits_path = input_dir / \"splits.json\"\n",
        "    if splits_path.exists():\n",
        "        with open(splits_path) as f:\n",
        "            split_data = json.load(f)\n",
        "            print(f\"Dataset stats: {split_data.get('stats', {})}\")\n",
        "\n",
        "    stats = {\"processed\": 0, \"filtered\": 0, \"augmented\": 0}\n",
        "\n",
        "    for split_name in dataset:\n",
        "        print(f\"\\nProcessing split: {split_name}\")\n",
        "        split_dir = output_dir / split_name\n",
        "        split_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        for i, sample in enumerate(dataset[split_name]):\n",
        "            audio_data = sample[\"audio\"][\"array\"]\n",
        "            sr = sample[\"audio\"][\"sampling_rate\"]\n",
        "\n",
        "            processed = preprocess_sample(audio_data, sr, target_sr)\n",
        "            if processed is None:\n",
        "                stats[\"filtered\"] += 1\n",
        "                continue\n",
        "\n",
        "            # Save processed audio\n",
        "            out_path = split_dir / f\"sample_{i:05d}.wav\"\n",
        "            sf.write(str(out_path), processed, target_sr)\n",
        "            stats[\"processed\"] += 1\n",
        "\n",
        "            # Augment only training data\n",
        "            if do_augment and split_name == \"train\":\n",
        "                for suffix, aug_audio in augment_sample(processed, target_sr):\n",
        "                    aug_path = split_dir / f\"sample_{i:05d}_{suffix}.wav\"\n",
        "                    sf.write(str(aug_path), aug_audio, target_sr)\n",
        "                    stats[\"augmented\"] += 1\n",
        "\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(f\"  Processed {i + 1} samples...\")\n",
        "\n",
        "    print(\n",
        "        f\"\\nDone. Processed: {stats['processed']}, \"\n",
        "        f\"Filtered: {stats['filtered']}, Augmented: {stats['augmented']}\"\n",
        "    )\n",
        "\n",
        "    # Save stats\n",
        "    with open(output_dir / \"preprocessing_stats.json\", \"w\") as f:\n",
        "        json.dump(stats, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01fe55e3",
      "metadata": {
        "id": "01fe55e3"
      },
      "source": [
        "## 6) `main()`: command-line interface\n",
        "\n",
        "The `main()` function:\n",
        "\n",
        "1. Defines command-line arguments:\n",
        "   - `--input`: folder containing `torgo_dataset/`\n",
        "   - `--output`: where to write processed audio\n",
        "   - `--sr`: target sample rate (default 16000)\n",
        "   - `--no-augment`: disables augmentation\n",
        "2. Parses args\n",
        "3. Calls `process_dataset(...)`\n",
        "\n",
        "The final:\n",
        "\n",
        "```python\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```\n",
        "\n",
        "means: *only run `main()` when this file is executed as a script*, not when imported as a module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1d43d47",
      "metadata": {
        "id": "c1d43d47"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'args' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m process_dataset(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     input_dir=Path(\u001b[43margs\u001b[49m.input),\n\u001b[32m      3\u001b[39m     output_dir=Path(args.output),\n\u001b[32m      4\u001b[39m     target_sr=args.sr,\n\u001b[32m      5\u001b[39m     do_augment=\u001b[38;5;129;01mnot\u001b[39;00m args.no_augment,\n\u001b[32m      6\u001b[39m )\n",
            "\u001b[31mNameError\u001b[39m: name 'args' is not defined"
          ]
        }
      ],
      "source": [
        "process_dataset(\n",
        "    input_dir=Path(\"torgo\"),\n",
        "    output_dir=Path(\"torgo/processed\"),\n",
        "    target_sr=16000,\n",
        "    do_augment=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19cbcd8d",
      "metadata": {
        "id": "19cbcd8d"
      },
      "source": [
        "## 8) Summary\n",
        "\n",
        "You can think of the script as:\n",
        "\n",
        "- **Data ingestion** (load dataset from disk)\n",
        "- **Canonicalization** (resample to 16 kHz, normalize)\n",
        "- **Cleanup** (trim silence, filter duration)\n",
        "- **Training diversification** (augment *train* only)\n",
        "- **Export** (write `.wav` files + stats JSON)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [
        {
          "file_id": "1-ydFxM8zlC71glAEuXrnxKOl4H5CVkvk",
          "timestamp": 1771605352542
        }
      ]
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
